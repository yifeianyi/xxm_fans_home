# 粉丝数数据分析功能实现方案

## 一、功能概述

本方案实现基于 B站粉丝数爬虫数据的完整数据分析功能，包括后端数据模型、API 接口以及前后端适配联调。

### 核心功能
1. **账号粉丝数追踪**：追踪多个 B站账号（咻咻满、咻小满等）的粉丝数变化
2. **多粒度时间聚合**：支持小时级、日级、月级数据查询
3. **趋势可视化**：展示粉丝总量积累和净增长趋势
4. **自动化数据采集**：每小时自动爬取并存储粉丝数据

## 二、现有基础

### 2.1 爬虫脚本
**位置**：`spider/get_bilibili_fans_count.py`

**功能**：
- 获取指定 B站账号的粉丝数
- 支持多账号查询
- 数据按年月目录结构存储

**输出格式**：JSON 格式，包含 `update_time` 和 `accounts` 数组

**定时任务**：
- 位置：`scripts/bilibili_fans_count_cron.sh`
- 频率：每小时执行一次
- 日志：`logs/bilibili_fans_count.json`
- **自动化导入**：爬虫成功后自动调用导入脚本

### 2.2 前端数据结构
**位置**：`repo/xxm_fans_frontend/domain/types.ts`

已定义的类型：
- `TimeGranularity`: 'HOUR' | 'DAY' | 'MONTH'
- `DataPoint`: { time, value, delta }
- `AccountData`: { id, name, totalFollowers, history }

### 2.3 现有后端架构
应用：`data_analytics`

**已有模型**：WorkStatic、WorkMetricsHour、CrawlSession

## 三、后端实现

### 3.1 数据模型设计

#### 3.1.1 账号配置表
**文件**：`repo/xxm_fans_backend/data_analytics/models/account.py`

**字段**：
- `id`: 主键
- `uid`: 账号 UID（唯一）
- `name`: 账号名称
- `platform`: 平台（目前仅 bilibili）
- `is_active`: 是否启用
- `created_at`, `updated_at`: 时间戳

**索引**：platform+uid、is_active

#### 3.1.2 粉丝数据表
**文件**：`repo/xxm_fans_backend/data_analytics/models/follower_metrics.py`

**字段**：
- `account`: 外键关联 Account
- `follower_count`: 粉丝数
- `crawl_time`: 爬取时间
- `ingest_time`: 入库时间

**约束**：account + crawl_time 唯一

**索引**：account+crawl_time、crawl_time

### 3.2 Service 层实现

**文件**：`repo/xxm_fans_backend/data_analytics/services/follower_service.py`

#### 性能优化：预生成缓存机制

由于数据每小时更新一次，采用**预生成缓存策略**大幅降低后端压力：

**策略**：
1. 数据导入时预生成缓存（HOUR/DAY/MONTH 三种粒度）
2. 缓存存储：`data/cache/followers/` 目录
3. 缓存格式：JSON，与 API 响应格式一致
4. 有效期：60 分钟
5. API 查询优先读取缓存，无效则重新生成

**核心方法**：
- `get_all_accounts()`: 获取所有启用的账号列表
- `get_account_by_id()`: 根据 ID 获取账号
- `get_current_follower_count()`: 获取账号当前粉丝数
- `get_follower_history()`: 获取历史数据（支持时间聚合）
- `get_all_accounts_data()`: 获取所有账号完整数据（带缓存逻辑）
- `generate_cache()`: 生成指定粒度的缓存
- `generate_all_caches()`: 生成所有粒度的缓存
- `ingest_from_spider_data()`: 从爬虫数据导入

**数据聚合逻辑**：
- 使用 Django ORM 的 `TruncHour/TruncDay/TruncMonth` 函数
- 自动计算增量（delta = 当前值 - 前一值）
- 时间格式化：HOUR→"H:00", DAY→"MM-DD", MONTH→"YYYY-MM"

### 3.3 API 视图实现

**文件**：`repo/xxm_fans_backend/data_analytics/api/views.py`

**新增三个接口**：

1. **GET /api/data-analytics/followers/accounts/**
   - 功能：获取所有账号列表
   - 返回：账号基本信息（id, name, uid, platform）

2. **GET /api/data-analytics/followers/accounts/data/**
   - 功能：获取所有账号的粉丝数据
   - 参数：
     - granularity: 'HOUR' | 'DAY' | 'MONTH'（默认 DAY）
     - days: 查询天数（默认 30，范围 1-365）
   - 返回：AccountData 数组

3. **GET /api/data-analytics/followers/accounts/{account_id}/**
   - 功能：获取单个账号的详细数据
   - 参数：同上
   - 返回：单个 AccountData

**错误处理**：
- 参数验证（granularity 枚举、days 范围）
- 账号不存在返回 404
- 统一错误响应格式

### 3.4 URL 路由配置

**文件**：`repo/xxm_fans_backend/data_analytics/urls.py`

**新增路由**：
- `followers/accounts/` → accounts_list
- `followers/accounts/data/` → accounts_data
- `followers/accounts/<int:account_id>/` → account_detail

### 3.5 序列化器

**文件**：`repo/xxm_fans_backend/data_analytics/api/serializers.py`

**新增序列化器**：
- `AccountSerializer`: 账号基本信息
- `FollowerMetricsSerializer`: 粉丝指标数据

### 3.6 数据导入脚本

**文件**：`repo/xxm_fans_backend/tools/ingest_follower_data.py`

**功能**：
- 从爬虫 JSON 文件导入数据到数据库
- 导入成功后自动预生成缓存
- 支持单文件导入和批量导入

**核心逻辑**：
1. 读取 JSON 文件
2. 遍历 accounts 数组
3. 查找或创建 Account 记录
4. 保存 FollowerMetrics 记录（使用 update_or_create）
5. 调用 `generate_all_caches()` 预生成缓存

**使用方式**：
```bash
# 导入所有历史数据
python tools/ingest_follower_data.py

# 导入单个文件
python tools/ingest_follower_data.py --file data/spider/fans_count/2026/01/b_fans_count_2026-01-01-00.json
```

### 3.7 初始化数据迁移

**文件**：`repo/xxm_fans_backend/data_analytics/migrations/0002_initialize_accounts.py`

**功能**：创建初始账号配置（咻咻满、咻小满）

## 四、前端适配

### 4.1 API 接口适配

**文件**：`repo/xxm_fans_frontend/infrastructure/api/RealSongService.ts`

**新增方法**：
- `getAccounts()`: 获取账号数据（默认 DAY 粒度）
- `getAccountsWithGranularity()`: 获取指定粒度的账号数据
- `getAccountDetail()`: 获取单个账号详情

**特点**：
- 使用现有的 `apiClient.get()` 方法
- 统一错误处理
- 类型安全

### 4.2 页面组件适配

**文件**：`repo/xxm_fans_frontend/presentation/pages/DataAnalysisPage/index.tsx`

**修改点**：
1. 替换 `mockApi` 为 `songService`
2. 添加错误状态处理
3. 添加加载状态展示
4. 优化空状态提示

**状态管理**：
- `granularity`: 时间粒度
- `accounts`: 账号数据列表
- `selectedAccIdx`: 选中账号索引
- `loading`: 加载状态
- `error`: 错误信息

## 五、部署流程

### 5.1 后端部署

1. **创建数据库迁移**
```bash
cd /home/yifeianyi/Desktop/xxm_fans_home/repo/xxm_fans_backend
python manage.py makemigrations data_analytics
python manage.py migrate data_analytics
```

2. **导入历史数据**
```bash
# 导入所有历史数据（只需一次）
python tools/ingest_follower_data.py
```

3. **配置定时任务**
```bash
crontab -e
# 添加：0 * * * * /home/yifeianyi/Desktop/xxm_fans_home/scripts/bilibili_fans_count_cron.sh
```

**定时任务工作流程**：
```
每小时:00 → 爬虫启动 → 获取粉丝数 → 保存 JSON
  ↓
自动导入 → 写入数据库
  ↓
预生成缓存 → 3个缓存文件（HOUR/DAY/MONTH）
  ↓
记录日志
```

4. **验证数据**
```bash
python manage.py shell
>>> from data_analytics.models import Account, FollowerMetrics
>>> Account.objects.all()
>>> FollowerMetrics.objects.count()
```

### 5.2 前端部署

1. **更新代码**
2. **构建项目**：`npm run build`
3. **验证功能**：访问 `/data-analytics` 页面

## 六、测试计划

### 6.1 后端测试

1. **模型测试**：增删改查、唯一性约束、索引性能
2. **Service 测试**：各方法返回正确性
3. **API 测试**：curl 测试三个接口

### 6.2 前端测试

1. **功能测试**：页面加载、账号切换、粒度切换、图表渲染
2. **错误处理**：API 失败、无数据、网络超时
3. **性能测试**：大数据量加载、图表渲染、组件重渲染

## 七、监控与维护

### 7.1 数据导入监控

1. **定时任务日志**：`logs/bilibili_fans_count.json`
2. **数据质量检查**：完整性、异常值、时间连续性

### 7.2 性能监控

1. **数据库性能**：查询响应时间、索引使用、连接池
2. **API 性能**：响应时间、并发能力、错误率

## 八、未来扩展

1. **多平台支持**：微博、抖音等
2. **高级分析**：增长率、预测模型、异常检测
3. **数据导出**：CSV、Excel、图表
4. **实时推送**：WebSocket、阈值告警

## 九、附录

### 9.1 工具和文件清单

#### 数据采集工具
| 文件/目录 | 说明 |
|-----------|------|
| spider/get_bilibili_fans_count.py | B站粉丝数爬虫，每小时运行 |
| scripts/bilibili_fans_count_cron.sh | Cron 定时任务，自动爬取并导入 |
| data/spider/fans_count/ | 爬虫数据存储目录 |
| logs/bilibili_fans_count.json | 爬虫执行日志 |

#### 数据库和导入工具
| 文件/目录 | 说明 |
|-----------|------|
| tools/ingest_follower_data.py | 数据导入工具，导入后自动预生成缓存 |
| models/account.py | 账号配置数据模型 |
| models/follower_metrics.py | 粉丝数据模型 |
| services/follower_service.py | 粉丝数据业务逻辑，含缓存管理 |
| data/cache/followers/ | 预生成缓存存储目录 |

#### 缓存文件
| 文件 | 说明 | 更新频率 |
|------|------|---------|
| accounts_hour.json | HOUR 粒度数据 | 每小时 |
| accounts_day.json | DAY 粒度数据 | 每小时 |
| accounts_month.json | MONTH 粒度数据 | 每小时 |

#### API 接口
| 接口 | 方法 | 路径 | 说明 |
|------|------|------|------|
| 获取账号列表 | GET | /api/data-analytics/followers/accounts/ | 获取所有启用的账号 |
| 获取账号数据 | GET | /api/data-analytics/followers/accounts/data/ | 获取所有账号的粉丝数据 |
| 获取账号详情 | GET | /api/data-analytics/followers/accounts/{id}/ | 获取单个账号的详细数据 |

### 9.2 数据流完整流程

```
每小时定时任务触发
  ↓
爬虫启动（获取粉丝数）
  ↓
保存 JSON 文件
  ↓
【自动】导入到数据库
  ↓
【自动】预生成缓存（3个粒度）
  ↓
记录日志
  ↓
用户访问 API（直接读缓存，<10ms）
  ↓
前端展示
```

### 9.3 关键时间节点

| 时间点 | 事件 | 涉及工具 | 输出 | 备注 |
|--------|------|---------|------|------|
| :00 | 定时任务触发 | cron | - | - |
| :00-:02 | 爬虫执行 | get_bilibili_fans_count.py | JSON | - |
| :02-:03 | 自动导入 | ingest_follower_data.py | 数据库记录 | - |
| :03-:05 | 预生成缓存 | follower_service.py | 3个缓存文件 | - |
| :05+ | 用户访问 | REST API | - | 直接读缓存，<10ms |

### 9.4 数据库表结构

**data_analytics_account**
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| uid | String(50) | 账号 UID（唯一） |
| name | String(200) | 账号名称 |
| platform | String(50) | 平台 |
| is_active | Boolean | 是否启用 |
| created_at | DateTime | 创建时间 |
| updated_at | DateTime | 更新时间 |

**data_analytics_followermetrics**
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| account | ForeignKey | 关联账号 |
| follower_count | Integer | 粉丝数 |
| crawl_time | DateTime | 爬取时间 |
| ingest_time | DateTime | 入库时间 |

**索引**：
- Account: (platform, uid), (is_active)
- FollowerMetrics: (account, crawl_time), (crawl_time)

### 9.5 性能优化说明

**预生成缓存策略优势**：
- ✅ 数据库查询减少 99%（API 直接读缓存）
- ✅ 响应时间从 ~50-100ms 降至 <10ms
- ✅ 并发能力提升（文件可多次并发读取）
- ✅ 服务器负载降低（减少数据库资源消耗）

**缓存机制**：
- 缓存有效期：60 分钟
- 自动生成时机：数据导入后立即生成
- 缓存失效处理：过期时自动从数据库重新生成
- 缓存一致性：与数据更新频率一致（每小时）

### 9.6 数据验证机制

**导入验证**：
- 检查 JSON 格式正确性
- 验证必要字段（uid, name, follower）
- 处理失败账号（记录错误日志）
- 防止重复导入（使用 update_or_create）

**API 验证**：
- 参数类型检查
- 参数范围验证
- 账号存在性检查
- 缓存有效性验证

**监控告警**：
- 定时任务执行失败
- 数据导入成功率下降
- 缓存生成异常
- API 响应时间过长