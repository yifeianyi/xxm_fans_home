# 粉丝数数据分析功能 - 部署与使用总结

## 一、功能概述

粉丝数数据分析功能是一个完整的粉丝数据追踪和可视化系统，支持多账号、多时间粒度的数据展示和分析。

### 核心特性
- **多账号支持**：同时追踪多个B站账号的粉丝数变化
- **三种时间粒度**：过去24小时、过去7天、过去30天
- **自动数据采集**：定时任务每小时自动获取最新数据
- **智能缓存机制**：预生成缓存，提升API响应速度
- **可视化展示**：折线图展示粉丝数趋势，柱状图展示增量变化

### 技术架构
- **后端**：Django + Django REST Framework
- **前端**：React + TypeScript + Vite
- **数据库**：SQLite (view_data.sqlite3)
- **数据源**：B站API爬虫

---

## 二、功能部署上线

### 2.1 数据库模型

#### Account（账号表）
```python
- id: 账号ID
- name: 账号名称（如"咻咻满"）
- uid: B站用户ID
- platform: 平台（默认"bilibili"）
- is_active: 是否激活
- created_at: 创建时间
```

#### FollowerMetrics（粉丝数据表）
```python
- id: 记录ID
- account: 关联账号
- follower_count: 粉丝数
- crawl_time: 爬取时间
- created_at: 创建时间
```

### 2.2 后端API接口

#### 获取所有账号数据
```
GET /api/data-analytics/followers/accounts/data/?granularity=WEEK&days=7

参数:
  - granularity: 时间粒度（DAY/WEEK/MONTH）
  - days: 查询天数

返回:
  - 账号列表，包含：
    - id, name, uid, platform
    - totalFollowers: 总粉丝数
    - history: 历史数据（按粒度）
      - time: 时间标签
      - value: 粉丝数
      - delta: 增量
```

#### 获取单个账号详情
```
GET /api/data-analytics/followers/accounts/{account_id}/?granularity=WEEK&days=7

参数:
  - account_id: 账号ID
  - granularity: 时间粒度
  - days: 查询天数

返回:
  - 账号详细信息 + 历史数据
```

### 2.3 前端组件

#### TrendChart（趋势图组件）
- 支持折线图和柱状图
- 自动调整Y轴刻度和数字格式
- 悬停显示详细数据
- 根据粒度自动调整X轴刻度数量

#### OverviewSection（概览区域）
- 账号切换按钮
- 时间粒度切换按钮（过去24小时/过去7天/过去30天）
- 展示当前粉丝数、总增减、平均增减

### 2.4 缓存机制

#### 缓存文件位置
```
repo/xxm_fans_backend/data/cache/followers/
├── accounts_day.json    # 小时级数据（过去24小时）
├── accounts_week.json   # 天级数据（过去7天）
└── accounts_month.json  # 天级数据（过去30天）
```

#### 缓存生成策略
- **DAY粒度**：使用小时分桶（TruncHour），显示时间格式 "14:00"
- **WEEK粒度**：使用天分桶（TruncDay），显示日期格式 "2026/01/02"
- **MONTH粒度**：使用月分桶（TruncMonth），显示日期格式 "2026/01/02"

#### 缓存更新
每次数据导入后自动触发缓存预生成，无需手动操作。

---

## 三、数据导入流程

### 3.1 定时任务配置

#### Cron任务设置
```bash
# 每小时运行一次
0 * * * * /home/yifeianyi/Desktop/xxm_fans_home/scripts/bilibili_fans_count_cron.sh
```

### 3.2 完整数据流程

```
┌─────────────────┐
│  定时任务触发    │ (每小时)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  爬虫获取数据    │
│  get_bilibili_  │
│  fans_count.py  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  保存JSON文件   │
│  data/spider/   │
│  fans_count/    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  导入数据库     │
│  ingest_follower│
│  _data.py       │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  自动生成缓存   │
│  DAY/WEEK/MONTH│
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  前端API调用    │
│  读取缓存数据   │
└─────────────────┘
```

### 3.3 手动导入操作

#### 单文件导入
```bash
cd /home/yifeianyi/Desktop/xxm_fans_home
python3 repo/xxm_fans_backend/tools/ingest_follower_data.py \
  --file /path/to/b_fans_count_2026-02-01-19.json
```

#### 批量导入（历史数据）
```bash
cd /home/yifeianyi/Desktop/xxm_fans_home
python3 repo/xxm_fans_backend/tools/ingest_follower_data.py \
  --dir /home/yifeianyi/Desktop/xxm_fans_home/data/spider/fans_count
```

### 3.4 导入脚本功能

`ingest_follower_data.py` 支持以下功能：

1. **JSON文件解析**：读取爬虫生成的JSON文件
2. **账号自动匹配**：根据UID自动关联到Account表
3. **数据入库**：将粉丝数据插入FollowerMetrics表
4. **缓存预生成**：自动生成三种粒度的缓存文件
5. **冲突处理**：重复时间点的数据会跳过

#### 导入输出示例
```
正在导入文件: /path/to/b_fans_count_2026-02-01-19.json

导入结果:
  成功: 2
  失败: 0

开始预生成缓存...
开始预生成所有粒度的缓存...
✓ 缓存已生成: DAY (2 个账号)
✓ 缓存已生成: WEEK (2 个账号)
✓ 缓存已生成: MONTH (2 个账号)
所有缓存预生成完成
✓ 缓存预生成完成
```

---

## 四、配置说明

### 4.1 账号配置

#### 添加新账号
```python
# 方式1：通过Django Admin后台
# 访问 http://your-domain/admin/data_analytics/account/
# 手动添加账号信息

# 方式2：通过Python脚本
from data_analytics.services.follower_service import FollowerService
FollowerService.create_account(
    name="新账号名称",
    uid="B站用户ID",
    platform="bilibili"
)
```

#### 当前支持的账号
- 咻咻满 (uid: 388828249)
- 咻小满 (uid: 435525530)

### 4.2 爬虫配置

#### 爬虫脚本位置
```
spider/get_bilibili_fans_count.py
```

#### 支持的账号配置
```python
# 在爬虫脚本中配置
ACCOUNTS = {
    "咻咻满": "388828249",
    "咻小满": "435525530"
}
```

### 4.3 前端配置

#### 默认粒度
```typescript
// repo/xxm_fans_frontend/presentation/pages/DataAnalysisPage/index.tsx
const [granularity, setGranularity] = useState<TimeGranularity>('WEEK');
```

#### 横坐标刻度配置
```typescript
// TrendChart.tsx
DAY: 6个刻度（每4小时一个）
WEEK: 7个刻度（每天一个）
MONTH: 7个刻度（均匀分布）
```

---

## 五、监控与维护

### 5.1 日志监控

#### 定时任务日志
```
logs/bilibili_fans_count.json
```

#### 日志格式
```json
{
  "start_time": "2026-02-01 20:00:00",
  "end_time": "2026-02-01 20:00:05",
  "exit_code": 0,
  "status": "success",
  "error_message": "",
  "summary": "✓ 咻咻满: 2741463 粉丝\n✓ 咻小满: 129458 粉丝\n数据导入成功"
}
```

### 5.2 缓存管理

#### 手动重新生成缓存
```python
cd /home/yifeianyi/Desktop/xxm_fans_home/repo/xxm_fans_backend
python3 manage.py shell <<EOF
from data_analytics.services.follower_service import FollowerService
FollowerService.generate_all_caches()
EOF
```

#### 清理过期缓存
```bash
# 删除旧的缓存文件
rm -f data/cache/followers/*.json
# 重新生成
python3 manage.py shell -c "from data_analytics.services.follower_service import FollowerService; FollowerService.generate_all_caches()"
```

### 5.3 数据库维护

#### 检查数据完整性
```python
# 检查最近的记录
from data_analytics.models import FollowerMetrics
from datetime import datetime, timedelta

recent_records = FollowerMetrics.objects.filter(
    crawl_time__gte=datetime.now() - timedelta(days=7)
).order_by('-crawl_time')

print(f"最近7天记录数: {recent_records.count()}")
```

#### 清理历史数据（可选）
```python
# 保留最近90天的数据
from data_analytics.models import FollowerMetrics
from datetime import datetime, timedelta

cutoff_date = datetime.now() - timedelta(days=90)
deleted_count = FollowerMetrics.objects.filter(
    crawl_time__lt=cutoff_date
).delete()[0]

print(f"已删除 {deleted_count} 条历史记录")
```

---

## 六、故障排查

### 6.1 数据不显示

#### 检查1：缓存文件是否存在
```bash
ls -lh repo/xxm_fans_backend/data/cache/followers/
```

#### 检查2：数据库是否有数据
```python
from data_analytics.models import FollowerMetrics
print(FollowerMetrics.objects.count())
```

#### 检查3：API是否正常返回
```bash
curl http://localhost:8080/api/data-analytics/followers/accounts/data/?granularity=WEEK
```

### 6.2 爬虫失败

#### 检查爬虫日志
```bash
tail -f logs/bilibili_fans_count.json | jq '.'
```

#### 常见问题
- **网络问题**：检查B站API是否可访问
- **账号ID错误**：确认UID是否正确
- **反爬限制**：检查是否触发了B站反爬机制

### 6.3 缓存更新失败

#### 重新生成缓存
```bash
cd /home/yifeianyi/Desktop/xxm_fans_home/repo/xxm_fans_backend
python3 manage.py shell -c "from data_analytics.services.follower_service import FollowerService; FollowerService.generate_all_caches()"
```

---

## 七、扩展说明

### 7.1 添加新的时间粒度

如果需要添加新的时间粒度（如季度、年），需要修改：

1. **类型定义**
```typescript
// domain/types.ts
export type TimeGranularity = 'DAY' | 'WEEK' | 'MONTH' | 'QUARTER' | 'YEAR';
```

2. **后端服务**
```python
# data_analytics/services/follower_service.py
elif granularity == 'QUARTER':
    start_time = end_time - timedelta(days=days * 90)
    trunc_func = TruncQuarter('crawl_time')
```

3. **前端组件**
```typescript
// TrendChart.tsx
} else if (granularity === 'QUARTER') {
  time_str = item['time_bucket'].strftime('%Y/Q%q')
}
```

### 7.2 添加新的数据源

如果需要支持其他平台（如抖音、微博），需要：

1. 创建新的爬虫脚本
2. 在Account表中添加platform字段区分
3. 修改定时任务脚本支持多平台
4. 在前端展示时添加平台标识

---

## 八、总结

粉丝数数据分析功能已经完整部署上线，具备以下特点：

✅ **自动化**：定时任务每小时自动采集数据
✅ **高性能**：预生成缓存，API响应快速
✅ **可视化**：三种粒度的趋势图展示
✅ **可扩展**：支持多账号、多平台、多粒度
✅ **易维护**：完整的日志和监控机制

整个数据流程已经打通，从数据采集到前端展示完全自动化，无需人工干预即可持续运行。